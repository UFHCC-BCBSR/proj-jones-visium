---
title: "10x Visium FFPE Spatial Transcriptomics Analysis"
author: "Spatial Analysis Pipeline"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    theme: flatly
    code_folding: show
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.width = 12, fig.height = 8)
```

# Overview

This pipeline performs spatial transcriptomics analysis of 10x Visium FFPE samples using **standard Seurat QC filtering practices**. 

**Samples:** 8 total (Groups A and D, n=4 each)

**Quality Note:** These samples show FFPE-related quality challenges including low UMI counts and variable mapping rates. We use standard Seurat QC thresholds rather than complex adaptive filtering because:

1. **Elaborate filtering doesn't fix intrinsic FFPE degradation** - our initial tests showed minimal improvement
2. **Standard practices are reproducible and well-validated** - following Seurat documentation and community standards
3. **Simple thresholds are transparent** - easy to understand and justify
4. **We're not reinventing the wheel** - using established 10x Genomics and Seurat recommendations

**Standard QC approach:**
- Remove spots with <200 genes (likely empty or failed)
- Remove spots with >25% mitochondrial content (dead/dying cells)
- Remove extreme outliers (>99th percentile)

This is honest science: we acknowledge sample limitations and analyze what we have with appropriate caveats.

---

# Load Libraries

```{r load-libraries}
library(Seurat)
library(ggplot2)
library(patchwork)
library(dplyr)
library(tidyverse)
library(knitr)
library(kableExtra)
```

---

# Part 1: Load Samples and Calculate QC Metrics

```{r load-samples}
# Define sample information
sample_paths <- data.frame(
  sample_id = c("A1", "A2", "A3", "A4", "D1", "D2", "D3", "D4"),
  path = c("A1_AM_Spatial_Seq", "A2_AM_Spatial_Seq", "A3_AM_Spatial_Seq", "A4_AM_Spatial_Seq",
           "D1_AM_Spatial_Seq", "D2_AM_Spatial_Seq", "D3_AM_Spatial_Seq", "D4_AM_Spatial_Seq"),
  group = c(rep("A", 4), rep("D", 4)),
  stringsAsFactors = FALSE
)

cat("Loading spatial samples...\n")
spatial_list <- list()

for(i in 1:nrow(sample_paths)) {
  sample_id <- sample_paths$sample_id[i]
  sample_path <- sample_paths$path[i]
  
  cat(paste0("  Loading ", sample_id, "...\n"))
  
  tryCatch({
  # Load spatial data
    obj <- Load10X_Spatial(
      data.dir = paste0("/orange/cancercenter-dept/JONES/AM_10x_Visium_v2/SpaceRanger_Output_and_Scripts/",
                        sample_path, "/outs"),
      filename = "filtered_feature_bc_matrix.h5"
    )
    
  # Add sample metadata
    obj$sample_id <- sample_id
    obj$group <- sample_paths$group[i]
    
  # Calculate QC metrics
    obj$percent.mt <- PercentageFeatureSet(obj, pattern = "^MT-")
    obj$percent.ribo <- PercentageFeatureSet(obj, pattern = "^RP[SL]")
    
  # Handle NA values (spots with no MT genes)
    obj$percent.mt[is.na(obj$percent.mt)] <- 0
    obj$percent.ribo[is.na(obj$percent.ribo)] <- 0
    
    spatial_list[[sample_id]] <- obj
    cat(paste0("    Loaded ", ncol(obj), " spots\n"))
    
  }, error = function(e) {
    cat(paste0("    ERROR: ", e$message, "\n"))
  })
}

cat(paste0("\nSuccessfully loaded ", length(spatial_list), " samples\n"))
```

---

# Part 2: Pre-QC Visualization

```{r pre-qc-summary}
# Create summary of pre-QC metrics
pre_qc_summary <- data.frame()

for(sample_id in names(spatial_list)) {
  obj <- spatial_list[[sample_id]]
  
  pre_qc_summary <- rbind(pre_qc_summary, data.frame(
    Sample = sample_id,
    Group = unique(obj$group),
    Total_Spots = ncol(obj),
    Median_UMI = median(obj$nCount_Spatial),
    Median_Genes = median(obj$nFeature_Spatial),
    Mean_MT_Percent = round(mean(obj$percent.mt), 2),
    Spots_Low_Genes = sum(obj$nFeature_Spatial < 200),
    Spots_High_MT = sum(obj$percent.mt > 25)
  ))
}

kable(pre_qc_summary, 
      caption = "Pre-QC Summary Statistics") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

```{r pre-qc-plots, fig.width=14, fig.height=10}
# Generate pre-QC violin plots for all samples
for(sample_id in names(spatial_list)) {
  obj <- spatial_list[[sample_id]]
  
  p <- VlnPlot(obj, 
               features = c("nCount_Spatial", "nFeature_Spatial", "percent.mt"),
               ncol = 3, 
               pt.size = 0.1) +
    plot_annotation(title = paste0(sample_id, " - Pre-QC Metrics"))
  
  print(p)
}
```

---

# Part 3: Standard Seurat QC Filtering

## Filtering Rationale

We apply **standard Seurat QC thresholds** used widely in spatial transcriptomics:

**Filter 1: Minimum gene threshold (>200 genes)**
- **Purpose:** Remove empty spots, failed capture spots, or spots with insufficient RNA
- **Biological basis:** Spots with <200 genes lack sufficient complexity for meaningful analysis
- **Reference:** Standard Seurat filtering (Butler et al. 2018, Nature Biotechnology)

**Filter 2: Mitochondrial percentage threshold (<25%)**
- **Purpose:** Remove dead/dying cells with compromised cell membranes
- **Biological basis:** High MT% indicates cytoplasmic RNA loss with preserved mitochondrial RNA
- **FFPE consideration:** We use 25% (more permissive than 15-20% for fresh tissue) because FFPE can have higher background
- **Reference:** 10x Genomics technical notes for FFPE samples

**Filter 3: Remove extreme outliers (>99th percentile)**
- **Purpose:** Remove doublets, artifacts, or technical anomalies
- **Biological basis:** Spots with extreme counts likely represent technical issues
- **Statistical basis:** Outliers beyond 99th percentile are often non-biological

```{r standard-qc-filtering}
cat("\n")
cat(strrep("=", 80), "\n")
cat("APPLYING STANDARD SEURAT QC FILTERING\n")
cat(strrep("=", 80), "\n\n")

spatial_filtered <- list()
qc_summary <- data.frame()

for(sample_id in names(spatial_list)) {
  obj <- spatial_list[[sample_id]]
  
  cat(paste0("\nFiltering ", sample_id, ":\n"))
  
# Record pre-filter metrics
  n_spots_before <- ncol(obj)
  median_umi_before <- median(obj$nCount_Spatial)
  median_genes_before <- median(obj$nFeature_Spatial)
  mean_mt_before <- mean(obj$percent.mt)
  
# Calculate 99th percentile threshold for this sample
  upper_limit <- quantile(obj$nFeature_Spatial, 0.99)
  
  cat(paste0("  Initial spots: ", n_spots_before, "\n"))
  cat(paste0("  Thresholds:\n"))
  cat(paste0("    - Minimum genes: 200\n"))
  cat(paste0("    - Maximum MT%: 25%\n"))
  cat(paste0("    - Upper gene limit (99th percentile): ", round(upper_limit, 0), "\n"))
  
# Apply standard Seurat QC filtering
  obj_filtered <- subset(obj, 
                         subset = nFeature_Spatial > 200 & 
                                 nFeature_Spatial < upper_limit &
                                 percent.mt < 25)
  
# Record post-filter metrics
  n_spots_after <- ncol(obj_filtered)
  n_removed <- n_spots_before - n_spots_after
  pct_retained <- round(100 * n_spots_after / n_spots_before, 1)
  median_umi_after <- median(obj_filtered$nCount_Spatial)
  median_genes_after <- median(obj_filtered$nFeature_Spatial)
  mean_mt_after <- mean(obj_filtered$percent.mt)
  
  cat(paste0("  Spots retained: ", n_spots_after, " (", pct_retained, "%)\n"))
  cat(paste0("  Spots removed: ", n_removed, " (", round(100 - pct_retained, 1), "%)\n"))
  
# Store filtered object
  spatial_filtered[[sample_id]] <- obj_filtered
  
# Store summary
  qc_summary <- rbind(qc_summary, data.frame(
    Sample = sample_id,
    Group = unique(obj$group),
    Spots_Before = n_spots_before,
    Spots_After = n_spots_after,
    Spots_Removed = n_removed,
    Percent_Retained = pct_retained,
    Median_UMI_Before = median_umi_before,
    Median_UMI_After = median_umi_after,
    Median_Genes_Before = median_genes_before,
    Median_Genes_After = median_genes_after,
    Mean_MT_Before = round(mean_mt_before, 2),
    Mean_MT_After = round(mean_mt_after, 2)
  ))
}

cat("\n")
cat(strrep("=", 80), "\n")
cat("QC FILTERING COMPLETE\n")
cat(strrep("=", 80), "\n\n")
```

## QC Filtering Summary

```{r qc-summary-table}
kable(qc_summary, 
      caption = "QC Filtering Results - All Samples",
      digits = 1) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                font_size = 11) %>%
  scroll_box(width = "100%")

# Save summary
write.csv(qc_summary, "../results/QC_Filtering_Summary.csv", row.names = FALSE)

cat("\nQC summary saved to QC_Filtering_Summary.csv\n")
```

## Key Observations

```{r qc-observations, results='asis'}
# Calculate overall statistics
total_spots_before <- sum(qc_summary$Spots_Before)
total_spots_after <- sum(qc_summary$Spots_After)
overall_retention <- round(100 * total_spots_after / total_spots_before, 1)
avg_retention <- round(mean(qc_summary$Percent_Retained), 1)

cat(paste0("- **Total spots before QC:** ", format(total_spots_before, big.mark = ","), "\n"))
cat(paste0("- **Total spots after QC:** ", format(total_spots_after, big.mark = ","), "\n"))
cat(paste0("- **Overall retention rate:** ", overall_retention, "%\n"))
cat(paste0("- **Average retention per sample:** ", avg_retention, "%\n\n"))

# Identify samples with high removal rates
high_removal <- qc_summary %>% filter(Percent_Retained < 85)

if(nrow(high_removal) > 0) {
  cat("**Samples with >15% spot removal:**\n\n")
  for(i in 1:nrow(high_removal)) {
    cat(paste0("- ", high_removal$Sample[i], ": ", high_removal$Percent_Retained[i], 
               "% retained (removed ", high_removal$Spots_Removed[i], " spots)\n"))
  }
  cat("\n")
}

# Check if filtering improved metrics
improved <- qc_summary %>% 
  mutate(UMI_Improvement = Median_UMI_After - Median_UMI_Before) %>%
  filter(UMI_Improvement > 10)

if(nrow(improved) > 0) {
  cat("**Samples with notable UMI improvement (>10):**\n\n")
  for(i in 1:nrow(improved)) {
    cat(paste0("- ", improved$Sample[i], ": ", improved$Median_UMI_Before[i], 
               " -> ", improved$Median_UMI_After[i], " (+", 
               round(improved$UMI_Improvement[i], 0), ")\n"))
  }
} else {
  cat("**Note:** Filtering did not substantially improve median UMI counts. This indicates that low quality is **sample-wide** (FFPE degradation), not due to outlier spots. The samples are usable but have intrinsic limitations.\n")
}
```

---

# Part 4: Post-QC Visualization

```{r post-qc-plots, fig.width=14, fig.height=10}
cat("Generating post-QC visualizations...\n")

for(sample_id in names(spatial_filtered)) {
  obj <- spatial_filtered[[sample_id]]
  
# Violin plots
  p1 <- VlnPlot(obj, 
                features = c("nCount_Spatial", "nFeature_Spatial", "percent.mt"),
                ncol = 3, 
                pt.size = 0.1) +
    plot_annotation(title = paste0(sample_id, " - Post-QC Metrics"))
  
  print(p1)
  
# Spatial feature plots
  p2 <- SpatialFeaturePlot(obj, features = "nCount_Spatial") + 
    ggtitle(paste0(sample_id, " - UMI Counts"))
  p3 <- SpatialFeaturePlot(obj, features = "nFeature_Spatial") + 
    ggtitle(paste0(sample_id, " - Gene Counts"))
  p4 <- SpatialFeaturePlot(obj, features = "percent.mt") + 
    ggtitle(paste0(sample_id, " - Mitochondrial %"))
  
  print((p2 | p3) / p4)
}
```

---

# Part 5: Normalization and Dimensionality Reduction

## SCTransform Normalization

We use **SCTransform** (Hafemeister & Satija 2019, Genome Biology) for normalization because:

1. Accounts for sequencing depth differences between spots
2. Stabilizes variance across expression levels
3. Regresses out unwanted sources of variation (MT%)
4. Recommended for spatial transcriptomics data

```{r normalize-samples}
cat("Normalizing and processing samples...\n")

for(sample_id in names(spatial_filtered)) {
  rds_file <- paste0("../results/Filtered_", sample_id, "_Spatial.rds")
  
  if(file.exists(rds_file)) {
    cat(paste0("  Loading existing ", sample_id, " from disk...\n"))
    spatial_filtered[[sample_id]] <- readRDS(rds_file)
  } else {
    cat(paste0("  Processing ", sample_id, "...\n"))
    
    obj <- spatial_filtered[[sample_id]]
    
    # SCTransform normalization
    obj <- SCTransform(obj,
                       assay = "Spatial",
                       vars.to.regress = "percent.mt",
                       verbose = FALSE)
    
    # PCA for dimensionality reduction
    obj <- RunPCA(obj, assay = "SCT", npcs = 50, verbose = FALSE)
    
    # UMAP for visualization
    obj <- RunUMAP(obj, reduction = "pca", dims = 1:30, verbose = FALSE)
    
    # Clustering
    obj <- FindNeighbors(obj, reduction = "pca", dims = 1:30, verbose = FALSE)
    obj <- FindClusters(obj, resolution = 0.5, verbose = FALSE)
    
    spatial_filtered[[sample_id]] <- obj
    
    # Save processed object
    saveRDS(obj, file = rds_file)
  }
}

cat("All samples normalized and processed.\n")
```

```{r individual-sample-viz, fig.width=12, fig.height=6}
# Visualize individual samples
for(sample_id in names(spatial_filtered)) {
  obj <- spatial_filtered[[sample_id]]
  
  p1 <- DimPlot(obj, reduction = "umap", label = TRUE) + 
    ggtitle(paste0(sample_id, " - UMAP Clusters"))
  
  p2 <- SpatialDimPlot(obj, label = TRUE, label.size = 3) + 
    ggtitle(paste0(sample_id, " - Spatial Clusters"))
  
  print(p1 | p2)
}
```

---

# Part 6: Merge Samples by Group

```{r merge-groups}
cat("\n")
cat(strrep("=", 80), "\n")
cat("MERGING SAMPLES BY GROUP\n")
cat(strrep("=", 80), "\n\n")

# Separate samples by group
# Exclude A2 from Group A
group_A_samples <- spatial_filtered[c("A1", "A3", "A4")]  # Remove A2

cat(paste0("Group A samples (A2 excluded due to extreme low quality): ", 
           paste(names(group_A_samples), collapse = ", "), "\n"))
group_D_samples <- spatial_filtered[c("D1", "D3", "D4")] # Remove D2
cat(paste0("Group D samples (D2 excluded due to extreme low quality): ", 
           paste(names(group_D_samples), collapse = ", "), "\n"))
```

## Merge Group A

```{r merge-group-A}
rds_file_A <- "../results/Group_A_Merged_Spatial.rds"

if(file.exists(rds_file_A)) {
  cat("Loading existing Group A merged object from disk...\n")
  group_A_merged <- readRDS(rds_file_A)
  cat(paste0("  Loaded ", ncol(group_A_merged), " spots\n"))
} else {
  cat("Merging Group A samples...\n")
  
  if(length(group_A_samples) > 0) {
    # Merge samples
    group_A_merged <- merge(x = group_A_samples[[1]],
                            y = group_A_samples[-1],
                            add.cell.ids = names(group_A_samples),
                            project = "Group_A")
    
    cat(paste0("  Total spots: ", ncol(group_A_merged), "\n"))
    cat(paste0("  Total genes: ", nrow(group_A_merged), "\n\n"))
    
    # Re-normalize merged object
    cat("  Re-normalizing merged Group A...\n")
    group_A_merged <- SCTransform(group_A_merged,
                                  assay = "Spatial",
                                  vars.to.regress = "percent.mt",
                                  verbose = FALSE)
    
    # Dimensionality reduction
    group_A_merged <- RunPCA(group_A_merged, assay = "SCT", npcs = 50, verbose = FALSE)
    
    cat("  Group A processing complete.\n\n")
    
    # Save
    saveRDS(group_A_merged, file = rds_file_A)
  }
}

# Check for sample_id batch effect
DimPlot(group_A_merged, reduction="pca", group.by="sample_id")
```

## Integrate group A samples with harmony

```{r harmony-A }
# Check if harmony already run (object has harmony reduction)
if("harmony" %in% names(group_A_merged@reductions)) {
  cat("Harmony integration already completed for Group A\n")
} else {
  cat("Running Harmony integration for Group A...\n")
  library(harmony)
  
  # Run Harmony to integrate samples
  group_A_merged <- RunHarmony(group_A_merged,
                               group.by.vars = "sample_id",
                               dims = 1:30,
                               verbose = FALSE)
  
  # Use harmony reduction for UMAP and clustering
  group_A_merged <- RunUMAP(group_A_merged, reduction = "harmony", dims = 1:30)
  group_A_merged <- FindNeighbors(group_A_merged, reduction = "harmony", dims = 1:30)
  group_A_merged <- FindClusters(group_A_merged, resolution = 0.5)
  
  # Save updated object
  saveRDS(group_A_merged, file = "../results/Group_A_Merged_Spatial.rds")
  
  cat("  Group A Harmony complete.\n\n")
}

# Check for resolution of sample_id effect
DimPlot(group_A_merged, reduction="umap", group.by="sample_id")
DimPlot(group_A_merged, reduction="umap")
```

## Merge Group D

```{r merge-group-D}
rds_file_D <- "../results/Group_D_Merged_Spatial.rds"

if(file.exists(rds_file_D)) {
  cat("Loading existing Group D merged object from disk...\n")
  group_D_merged <- readRDS(rds_file_D)
  cat(paste0("  Loaded ", ncol(group_D_merged), " spots\n"))
} else {
  cat("Merging Group D samples...\n")
  
  if(length(group_D_samples) > 0) {
# Merge samples
  group_D_merged <- merge(x = group_D_samples[[1]],
                          y = group_D_samples[-1],
                          add.cell.ids = names(group_D_samples),
                          project = "Group_D")
  
  cat(paste0("  Total spots: ", ncol(group_D_merged), "\n"))
  cat(paste0("  Total genes: ", nrow(group_D_merged), "\n\n"))
  
# Re-normalize merged object
  cat("  Re-normalizing merged Group D...\n")
  # Group D
group_D_merged <- SCTransform(group_D_merged, 
                              assay = "Spatial",
                              vars.to.regress = "percent.mt", 
                              verbose = FALSE)
  
# Dimensionality reduction
group_D_merged <- RunPCA(group_D_merged, assay = "SCT", npcs = 50, verbose = FALSE)
# Save
    saveRDS(group_D_merged, file = rds_file_D)
  }
}
# Check for sample_id batch effect
DimPlot(group_D_merged,reduction="pca",group.by="sample_id")
```

```{r harmony-D }
if("harmony" %in% names(group_D_merged@reductions)) {
  cat("Harmony integration already completed for Group D\n")
} else {
  cat("Running Harmony integration for Group D...\n")
  
# Run Harmony to integrate samples
group_D_merged <- RunHarmony(group_D_merged, 
                             group.by.vars = "sample_id",
                             dims.use = 1:30,
                             verbose = FALSE)

# Use harmony reduction for UMAP and clustering
group_D_merged <- RunUMAP(group_D_merged, reduction = "harmony", dims = 1:30)
group_D_merged <- FindNeighbors(group_D_merged, reduction = "harmony", dims = 1:30)
group_D_merged <- FindClusters(group_D_merged, resolution = 0.5)
  saveRDS(group_D_merged, file = "../results/Group_D_Merged_Spatial.rds")
}

# Check for resolution of sample_id effect
DimPlot(group_D_merged,reduction="umap",group.by="sample_id")
DimPlot(group_D_merged,reduction="umap")
```

---

```{r merged-summary-stats}
# Summary of merged objects
summary_df <- data.frame(
  Group = c("A", "D"),
  Total_Spots = c(ncol(group_A_merged), ncol(group_D_merged)),
  Total_Genes = c(nrow(group_A_merged), nrow(group_D_merged)),
  N_Clusters = c(length(unique(group_A_merged$seurat_clusters)), 
                 length(unique(group_D_merged$seurat_clusters))),
  Median_UMI = c(median(group_A_merged$nCount_Spatial), 
                 median(group_D_merged$nCount_Spatial)),
  Median_Genes = c(median(group_A_merged$nFeature_Spatial), 
                   median(group_D_merged$nFeature_Spatial))
)

kable(summary_df, 
      caption = "Merged Group Summary Statistics",
      col.names = c("Group", "Total Spots", "Total Genes", "Clusters", "Median UMI", "Median Genes")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

---

# Part 8: Merged Object Visualizations

```{r merged-viz, fig.width=14, fig.height=10}
cat("Generating merged group visualizations...\n")

# GROUP A VISUALIZATIONS
cat("  Group A...\n")

p1 <- DimPlot(group_A_merged, reduction = "umap", group.by = "sample_id") +
  ggtitle("Group A - Colored by Sample") +
  theme_minimal()

p2 <- DimPlot(group_A_merged, reduction = "umap", group.by = "seurat_clusters", label = TRUE) +
  ggtitle("Group A - Colored by Cluster") +
  theme_minimal()

print(p1 | p2)

# QC metrics on UMAP
p3 <- FeaturePlot(group_A_merged, 
                  features = c("nCount_Spatial", "nFeature_Spatial"), 
                  reduction = "umap", 
                  ncol = 2)
print(p3)

# Check for batch effects
p4 <- VlnPlot(group_A_merged, 
              features = c("nCount_Spatial", "nFeature_Spatial"), 
              group.by = "sample_id", 
              pt.size = 0) +
  ggtitle("Group A - QC Metrics by Sample (Batch Effect Check)")
print(p4)

# Cluster composition by sample
cluster_comp_A <- table(group_A_merged$sample_id, group_A_merged$seurat_clusters)
cluster_comp_A_pct <- prop.table(cluster_comp_A, margin = 1) * 100

cluster_df_A <- as.data.frame(cluster_comp_A_pct)
colnames(cluster_df_A) <- c("Sample", "Cluster", "Percentage")

p5 <- ggplot(cluster_df_A, aes(x = Sample, y = Percentage, fill = Cluster)) +
  geom_bar(stat = "identity") +
  labs(title = "Group A - Cluster Composition by Sample",
       y = "Percentage of Spots") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p5)

# GROUP D VISUALIZATIONS
cat("  Group D...\n")

p6 <- DimPlot(group_D_merged, reduction = "umap", group.by = "sample_id") +
  ggtitle("Group D - Colored by Sample") +
  theme_minimal()

p7 <- DimPlot(group_D_merged, reduction = "umap", group.by = "seurat_clusters", label = TRUE) +
  ggtitle("Group D - Colored by Cluster") +
  theme_minimal()

print(p6 | p7)

p8 <- FeaturePlot(group_D_merged, 
                  features = c("nCount_Spatial", "nFeature_Spatial"), 
                  reduction = "umap", 
                  ncol = 2)
print(p8)

p9 <- VlnPlot(group_D_merged, 
              features = c("nCount_Spatial", "nFeature_Spatial"), 
              group.by = "sample_id", 
              pt.size = 0) +
  ggtitle("Group D - QC Metrics by Sample (Batch Effect Check)")
print(p9)

cluster_comp_D <- table(group_D_merged$sample_id, group_D_merged$seurat_clusters)
cluster_comp_D_pct <- prop.table(cluster_comp_D, margin = 1) * 100

cluster_df_D <- as.data.frame(cluster_comp_D_pct)
colnames(cluster_df_D) <- c("Sample", "Cluster", "Percentage")

p10 <- ggplot(cluster_df_D, aes(x = Sample, y = Percentage, fill = Cluster)) +
  geom_bar(stat = "identity") +
  labs(title = "Group D - Cluster Composition by Sample",
       y = "Percentage of Spots") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p10)
```

---

# Part 9: Find Cluster Markers

## Find cluster markers for group A

```{r find-markers-A}
# Join all layers into single layers
group_A_merged[["Spatial"]] <- JoinLayers(group_A_merged[["Spatial"]])

# Verify layers are joined
Layers(group_A_merged, assay = "Spatial")
group_A_merged <- NormalizeData(group_A_merged, assay = "Spatial", verbose = TRUE)

# Set default assay and identities
DefaultAssay(group_A_merged) <- "Spatial"
Idents(group_A_merged) <- group_A_merged$seurat_clusters

markers_A <- FindAllMarkers(group_A_merged,
                            only.pos = TRUE,
                            min.pct = 0.05,
                            logfc.threshold = 0.15,
                            test.use = "wilcox",
                            verbose = TRUE)

cat(paste0("Found ", nrow(markers_A), " markers\n"))

top10_A <- markers_A %>%
  group_by(cluster) %>%
  top_n(n = 10, wt = avg_log2FC)

write.csv(markers_A, "../results/Group_A_Cluster_Markers.csv", row.names = FALSE)
write.csv(top10_A, "../results/Group_A_Top10_Markers.csv", row.names = FALSE)

cat(paste0("  Found markers for ", length(unique(markers_A$cluster)), " clusters\n"))
cat(paste0("  Total marker genes: ", nrow(markers_A), "\n"))
cat("  Saved to ../results/Group_A_Cluster_Markers.csv\n")

```

## Find cluster markers for Group D

```{r find-markers-D}
# Join all layers into single layers
group_D_merged[["Spatial"]] <- JoinLayers(group_D_merged[["Spatial"]])

# Verify layers are joined
Layers(group_D_merged, assay = "Spatial")
group_D_merged <- NormalizeData(group_D_merged, assay = "Spatial", verbose = TRUE)

# Set default assay and identities
DefaultAssay(group_D_merged) <- "Spatial"
Idents(group_D_merged) <- group_D_merged$seurat_clusters

markers_D <- FindAllMarkers(group_D_merged,
                            only.pos = TRUE,
                            min.pct = 0.01,
                            logfc.threshold = 0.15,
                            test.use = "wilcox",
                            verbose = TRUE)

cat(paste0("Found ", nrow(markers_D), " markers\n"))

top10_D <- markers_D %>%
  group_by(cluster) %>%
  top_n(n = 10, wt = avg_log2FC)

write.csv(markers_A, "../results/Group_D_Cluster_Markers.csv", row.names = FALSE)
write.csv(top10_A, "../results/Group_D_Top10_Markers.csv", row.names = FALSE)

cat(paste0("  Found markers for ", length(unique(markers_A$cluster)), " clusters\n"))
cat(paste0("  Total marker genes: ", nrow(markers_A), "\n"))
cat("  Saved to ../results/Group_D_Cluster_Markers.csvn\n")

```

## Top Markers Preview

### Group A

```{r preview-markers-A}
top3_A <- markers_A %>%
  group_by(cluster) %>%
  top_n(n = 3, wt = avg_log2FC) %>%
  select(cluster, gene, avg_log2FC, pct.1, pct.2, p_val_adj)

kable(top3_A, 
      digits = 3, 
      caption = "Top 3 Markers per Cluster - Group A") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  scroll_box(height = "400px")
```

### Group D

```{r preview-markers-D}
top3_D <- markers_D %>%
  group_by(cluster) %>%
  top_n(n = 3, wt = avg_log2FC) %>%
  select(cluster, gene, avg_log2FC, pct.1, pct.2, p_val_adj)

kable(top3_D, 
      digits = 3, 
      caption = "Top 3 Markers per Cluster - Group D") %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  scroll_box(height = "400px")
```

---

# Part 11: Visualize Cluster Markers

```{r viz-markers, results='hide', fig.show='hide'}
cat("Generating marker visualization plots...\n")

pdf("../results/Cluster_Markers_Visualization.pdf", width = 20, height = 14)

# Group A - top 3 markers per cluster
cat("  Plotting Group A markers...\n")
top3_viz_A <- markers_A %>%
  group_by(cluster) %>%
  top_n(n = 3, wt = avg_log2FC)

for(clust in unique(top3_viz_A$cluster)) {
  genes <- top3_viz_A %>% filter(cluster == clust) %>% pull(gene)
  
  tryCatch({
  # Spatial feature plots
    p_spatial <- SpatialFeaturePlot(group_A_merged, 
                                    features = genes,
                                    ncol = 3,
                                    pt.size.factor = 1.6) +
      plot_annotation(title = paste0("Group A - Cluster ", clust, " Markers"))
    
  # Violin plots
    p_vln <- VlnPlot(group_A_merged, features = genes, ncol = 3, pt.size = 0) +
      plot_annotation(title = paste0("Group A - Cluster ", clust))
    
    print(p_spatial)
    print(p_vln)
  }, error = function(e) {
    cat(paste0("    Error plotting cluster ", clust, ": ", e$message, "\n"))
  })
}

# Group D - top 3 markers per cluster
cat("  Plotting Group D markers...\n")
top3_viz_D <- markers_D %>%
  group_by(cluster) %>%
  top_n(n = 3, wt = avg_log2FC)

for(clust in unique(top3_viz_D$cluster)) {
  genes <- top3_viz_D %>% filter(cluster == clust) %>% pull(gene)
  
  tryCatch({
    p_spatial <- SpatialFeaturePlot(group_D_merged, 
                                    features = genes,
                                    ncol = 3,
                                    pt.size.factor = 1.6) +
      plot_annotation(title = paste0("Group D - Cluster ", clust, " Markers"))
    
    p_vln <- VlnPlot(group_D_merged, features = genes, ncol = 3, pt.size = 0) +
      plot_annotation(title = paste0("Group D - Cluster ", clust))
    
    print(p_spatial)
    print(p_vln)
  }, error = function(e) {
    cat(paste0("    Error plotting cluster ", clust, ": ", e$message, "\n"))
  })
}

dev.off()

cat("Marker visualizations saved to ../results/Cluster_Markers_Visualization.pdf\n")
```

## View cluster markers on clusers in UMAP space

### Group A

```{r markers-dimplot}
# Top 3 markers for each cluster on UMAP
top3_A <- markers_A %>%
  group_by(cluster) %>%
  top_n(n = 3, wt = avg_log2FC)

# Feature plots on UMAP
for(clust in unique(top3_A$cluster)) {
  genes <- top3_A %>% filter(cluster == clust) %>% pull(gene)
  
  p <- FeaturePlot(group_A_merged, 
                   features = genes,
                   reduction = "umap",
                   ncol = 3,
                   order = TRUE) +  # Plot high expression on top
    plot_annotation(title = paste0("Cluster ", clust, " Top Markers"))
  
  print(p)
}
```

### Group D

```{r markers-dimplot-B}
# Top 3 markers for each cluster on UMAP
top3_B <- markers_D %>%
  group_by(cluster) %>%
  top_n(n = 3, wt = avg_log2FC)

# Feature plots on UMAP
for(clust in unique(top3_D$cluster)) {
  genes <- top3_D %>% filter(cluster == clust) %>% pull(gene)
  
  p <- FeaturePlot(group_D_merged, 
                   features = genes,
                   reduction = "umap",
                   ncol = 3,
                   order = TRUE) +  # Plot high expression on top
    plot_annotation(title = paste0("Cluster ", clust, " Top Markers"))
  
  print(p)
}
```

## Placenta specific markers

Our cluster markers don't show good localization to clusters and other than clusters 3 and 5, clusters might be technical artifacts. Let's focus on biologically known markers instead.

### Group A

```{r placenta-A}
# Placenta-specific markers
placenta_markers <- list(
  Trophoblast = c("CGB", "CGB3", "CGB5", "CGB7", "CSH1", "CSH2", "KRT7", "ERVW1", "PSG1"),
  Endothelial = c("PECAM1", "VWF", "CDH5", "CD34"),
  Stromal_Fibroblast = c("VIM", "COL1A1", "COL3A1", "DCN"),
  Smooth_Muscle = c("ACTA2", "MYH11", "TAGLN"),
  Immune = c("PTPRC", "CD68", "CD163", "CD3D"),
  Hofbauer_Cells = c("CD68", "CD163", "FOLR2")  # Placental macrophages
)

# Check which are detected
group_A_detected <- lapply(placenta_markers, function(genes) {
  genes[genes %in% rownames(group_A_merged)]
})

print(group_A_detected)

# Visualize on UMAP
for(cell_type in names(group_A_detected)) {
  if(length(group_A_detected[[cell_type]]) > 0) {
    p <- FeaturePlot(group_A_merged, 
                     features = group_A_detected[[cell_type]][1:min(4, length(group_A_detected[[cell_type]]))],
                     reduction = "umap",
                     ncol = 2)
    print(p + plot_annotation(title = paste0(cell_type, " Markers")))
  }
}

# DotPlot for all detected markers - remove duplicates
unique_markers <- unique(unlist(group_A_detected))

if(length(unique_markers) > 0) {
  DotPlot(group_A_merged, features = unique_markers) +
    RotatedAxis() +
    coord_flip() +
    ggtitle("Placental Cell Type Markers - Group A")
} else {
  cat("No placental markers detected in Group A\n")
}
```

### Group D

```{r placenta-D}
# Check which are detected
group_D_detected <- lapply(placenta_markers, function(genes) {
  genes[genes %in% rownames(group_D_merged)]
})

print(group_D_detected)

# Visualize on UMAP
for(cell_type in names(group_D_detected)) {
  if(length(group_D_detected[[cell_type]]) > 0) {
    p <- FeaturePlot(group_D_merged, 
                     features = group_D_detected[[cell_type]][1:min(4, length(group_D_detected[[cell_type]]))],
                     reduction = "umap",
                     ncol = 2)
    print(p + plot_annotation(title = paste0(cell_type, " Markers")))
  }
}

# DotPlot for all detected markers - remove duplicates
D_unique_markers <- unique(unlist(group_D_detected))

if(length(D_unique_markers) > 0) {
  DotPlot(group_D_merged, features = D_unique_markers) +
    RotatedAxis() +
    coord_flip() +
    ggtitle("Placental Cell Type Markers - Group D")
} else {
  cat("No placental markers detected in Group D\n")
}
```

---

# Part 12: Differential Expression Between Groups

## Merge All Samples for Group Comparison

```{r merge-all-samples}
rds_file_all <- "../results/All_Samples_Merged_Spatial.rds"

if(file.exists(rds_file_all)) {
  cat("Loading existing all-samples merged object from disk...\n")
  all_samples_merged <- readRDS(rds_file_all)
  cat(paste0("  Loaded ", ncol(all_samples_merged), " spots\n"))
} else {
  
cat("\n")
cat(strrep("=", 80), "\n")
cat("DIFFERENTIAL EXPRESSION: GROUP A vs GROUP D\n")
cat(strrep("=", 80), "\n\n")

cat("**Important Note:** This comparison assumes matched tissue regions and cell types.\n")
cat("If tissue composition differs between groups, results may be confounded by\n")
cat("compositional differences rather than true gene expression changes.n\n")

cat("Merging all samples for group comparison...\n")

# Don't regress sample_id - only regress percent.mt
all_samples_merged <- SCTransform(all_samples_merged, 
                                  assay = "Spatial",
                                  vars.to.regress = "percent.mt",  # Removed sample_id
                                  verbose = FALSE)

all_samples_merged <- RunPCA(all_samples_merged, assay = "SCT", npcs = 50, verbose = FALSE)

# Use Harmony for batch correction
library(harmony)
all_samples_merged <- RunHarmony(all_samples_merged, 
                                 group.by.vars = "sample_id",
                                 dims = 1:30,
                                 verbose = FALSE)

# Use harmony reduction for downstream analysis
all_samples_merged <- RunUMAP(all_samples_merged, reduction = "harmony", dims = 1:30, verbose = FALSE)
all_samples_merged <- FindNeighbors(all_samples_merged, reduction = "harmony", dims = 1:30, verbose = FALSE)
all_samples_merged <- FindClusters(all_samples_merged, resolution = 0.5, verbose = FALSE)
saveRDS(all_samples_merged, "../results/All_Samples_Merged_Spatial.rds")
saveRDS(all_samples_merged, file = rds_file_all)
  cat("All samples merged and processed.\n")
}
```

## Pseudobulk Differential Expression Analysis

### Rationale

**Why Clusters 3 and 5?**

During cluster marker analysis, only clusters 3 and 5 showed biologically meaningful, cluster-specific gene expression patterns. The other clusters appear to be driven by technical artifacts (sample quality differences, degradation patterns) rather than distinct cell populations. Therefore, we focus differential expression analysis on these two biologically interpretable clusters.

**Why Pseudobulk?**

Pseudobulk aggregation treats each biological sample as a replicate (rather than each individual spot), which:
- Provides appropriate statistical inference at the sample level
- Accounts for within-sample correlation of spots
- Follows current best practices for multi-sample spatial/single-cell analysis
- Allows use of edgeR's robust statistical framework designed for biological replicates

**Samples Included:**
- Group A: A3, A4 (n=2)
- Group D: D1, D3, D4 (n=3)

Samples A1, A2, and D2 were excluded due to severe quality issues (low UMI counts, poor mapping rates).

---

```{r pseudobulk-degs}
library(edgeR)

# Subset to quality-filtered samples
samples_to_use <- c("A3", "A4", "D1", "D3", "D4")
all_samples_subset <- subset(all_samples_merged, subset = sample_id %in% samples_to_use)

cat(paste0("Analyzing ", ncol(all_samples_subset), " spots from ", 
           length(samples_to_use), " samples\n\n"))

# Join layers (Seurat v5 requirement)
all_samples_subset[["Spatial"]] <- JoinLayers(all_samples_subset[["Spatial"]])

# Function to run pseudobulk DE for a cluster
run_pseudobulk_de <- function(seurat_obj, cluster_id, cluster_name) {
  
  cat(strrep("=", 60), "\n")
  cat(paste0("CLUSTER ", cluster_id, ": ", cluster_name, "\n"))
  cat(strrep("=", 60), "\n\n")
  
  # Subset to cluster
  cluster_obj <- subset(seurat_obj, subset = seurat_clusters == cluster_id)
  
  cat(paste0("Total spots: ", ncol(cluster_obj), "\n"))
  cat(paste0("  Group A: ", sum(cluster_obj$group == "Group_A"), "\n"))
  cat(paste0("  Group D: ", sum(cluster_obj$group == "Group_D"), "\n\n"))
  
  # Aggregate to pseudobulk (one value per sample)
  pseudo_obj <- AggregateExpression(cluster_obj,
                                    assays = "Spatial",
                                    return.seurat = TRUE,
                                    group.by = c("sample_id", "seurat_clusters"))
  
  # Add group metadata
  pseudo_obj$group <- ifelse(pseudo_obj$sample_id %in% c("A3", "A4"), 
                             "Group_A", "Group_D")
  
  cat("Pseudobulk samples:\n")
  print(table(pseudo_obj$group))
  cat("\n")
  
  # Extract counts and create design
  counts_matrix <- GetAssayData(pseudo_obj, assay = "Spatial", slot = "counts")
  group_factor <- factor(pseudo_obj$group, levels = c("Group_A", "Group_D"))
  design_matrix <- model.matrix(~group_factor)
  
  # edgeR analysis
  dge_list <- DGEList(counts = counts_matrix, group = group_factor)
  dge_list <- calcNormFactors(dge_list)
  dge_list <- estimateDisp(dge_list, design_matrix)
  fit_obj <- glmQLFit(dge_list, design_matrix)
  test_obj <- glmQLFTest(fit_obj, coef = 2)
  
  # Get all results
  results_all <- topTags(test_obj, n = Inf)$table
  results_all$gene <- rownames(results_all)
  
  # Filter significant
  results_sig <- results_all %>%
    filter(FDR < 0.05) %>%
    arrange(desc(abs(logFC)))
  
  # Report results
  cat(paste0("Total DEGs (FDR < 0.05): ", nrow(results_sig), "\n"))
  if(nrow(results_sig) > 0) {
    cat(paste0("  Upregulated in Group A: ", sum(results_sig$logFC > 0), "\n"))
    cat(paste0("  Upregulated in Group D: ", sum(results_sig$logFC < 0), "\n\n"))
  } else {
    cat("  No significant DEGs found\n\n")
  }
  
  # Save full results
  filename_all <- paste0("../results/Pseudobulk_Cluster", cluster_id, "_AllGenes.csv")
  filename_sig <- paste0("../results/Pseudobulk_Cluster", cluster_id, "_SignificantDEGs.csv")
  
  write.csv(results_all, filename_all, row.names = FALSE)
  write.csv(results_sig, filename_sig, row.names = FALSE)
  
  cat(paste0("Results saved:\n"))
  cat(paste0("  - ", filename_all, " (all genes)\n"))
  cat(paste0("  - ", filename_sig, " (FDR < 0.05 only)\n\n"))
  
  return(list(all = results_all, significant = results_sig))
}

# Run analysis for both clusters
degs_cluster3 <- run_pseudobulk_de(all_samples_subset, 
                                   cluster_id = 3, 
                                   cluster_name = "Biologically Meaningful Cluster 1")

degs_cluster5 <- run_pseudobulk_de(all_samples_subset, 
                                   cluster_id = 5, 
                                   cluster_name = "Biologically Meaningful Cluster 2")

cat(strrep("=", 60), "\n")
cat("PSEUDOBULK ANALYSIS COMPLETE\n")
cat(strrep("=", 60), "\n")
```

---

# Session Information

```{r session-info}
sessionInfo()
```

---

**Analysis completed:** `r Sys.time()`

**Document generated by:** 10x Visium FFPE Spatial Analysis Pipeline

**Key Reference:** This analysis follows standard Seurat workflows (https://satijalab.org/seurat/) and 10x Genomics best practices for FFPE spatial transcriptomics.
